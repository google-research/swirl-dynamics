{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOC77a4MazQ2BaofLLvn6lM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "iZXu1yA95VhR"
      },
      "cell_type": "markdown",
      "source": [
        "## Solving regularized Optimal Transport using Sinkhorn Iterations\n",
        "\n",
        "This short colabs provides a lightweight interface for the computation of the\n",
        "optimal transport map used for the debiasing step in this [paper](https://openreview.net/forum?id=5NxJuc0T1P).\n",
        "\n",
        "We consider the simpler case of the data stemming from solving the Kuramoto-Sivashinsky equation in 1D. We provide some simple statistical metrics for quick evaluation.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "x1ihDQGP5VhR"
      },
      "cell_type": "markdown",
      "source": [
        "### Downloading dependencies\n",
        "\n",
        "The only non-trivial dependency is ott-jax, a flexible tool box for solving optimal transport problems in jax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfVz51K9FjmA",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732068716984,
          "user_tz": 480,
          "elapsed": 2597,
          "user": {
            "displayName": "Leonardo Zepeda-Núñez",
            "userId": "15785928026062780104"
          }
        },
        "outputId": "09f5b7ec-bd0a-4b0c-bc67-d148da9dd9fe"
      },
      "outputs": [],
      "source": [
        "!pip install ott-jax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "jax.config.update(\"jax_enable_x64\", True)\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import ott\n",
        "from ott.tools import plot, sinkhorn_divergence\n",
        "from ott.geometry import costs, pointcloud\n",
        "from ott.problems.linear import linear_problem\n",
        "from ott.solvers.linear import sinkhorn"
      ],
      "metadata": {
        "id": "mix3B7emFm5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading the data from the google cloud bucket.\n",
        "\n",
        "The data was generated using [jax-cfd](https://github.com/google/jax-cfd), and uploaded to a Google Cloud bucket. The file contains both high- and low-resolution datasets.\n",
        "\n",
        "We use gsutil for downloading the data. If you are running this notebook in colab, it should be already installed, otherwise, you can follow these [instructions](https://cloud.google.com/storage/docs/gsutil_install)."
      ],
      "metadata": {
        "id": "DbTCLO7rn03N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp gs://gresearch/swirl_dynamics/downscaling/KS_finite_volumes_vs_pseudo_spectral.hdf5 ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl6aCgmoH7Cp",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732068721979,
          "user_tz": 480,
          "elapsed": 3615,
          "user": {
            "displayName": "Leonardo Zepeda-Núñez",
            "userId": "15785928026062780104"
          }
        },
        "outputId": "a511474f-fc5e-4d07-8a78-81b37a552ee9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = 'KS_finite_volumes_vs_pseudo_spectral.hdf5'\n",
        "\n",
        "with h5py.File(file_name,'r+') as f1:\n",
        "    # Trajectories with finite volumes.\n",
        "    u_lr    = f1['u_fd'][()]\n",
        "    # Trajectories with pseudo spectral methods.\n",
        "    u_hr    = f1['u_sp'][()]\n",
        "    # Time stamps for the trajectories.\n",
        "    t    = f1['t'][()]\n",
        "    # Grid in which the trajectories are computed. 512 equispaced points with\n",
        "    # periodic boundary conditions.\n",
        "    x    = f1['x'][()]"
      ],
      "metadata": {
        "id": "SmmL_3fqGZyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the low-res data.\n",
        "# We choose which trajectory we want to plot.\n",
        "plot_idx = 1\n",
        "# Spatial downsampling factor.\n",
        "ds_x = 4\n",
        "\n",
        "# Define domain in time and space.\n",
        "t_ = t\n",
        "x_ = jnp.concatenate([x, jnp.array(x[-1] + x[1] - x[0]).reshape((-1,))])[::ds_x]\n",
        "print(f\"Shape of the spatial domain: {x_.shape}\")\n",
        "\n",
        "# Plots the low-resolution data.\n",
        "fig = plt.figure(figsize=(14, 4))\n",
        "plt.imshow(u_lr[plot_idx, :, :].T)\n",
        "plt.xlabel(\"time\")\n",
        "plt.ylabel(\"x\")\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(x_, u_lr[plot_idx, 0, :])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YzAOtWz7IgiY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732068723729,
          "user_tz": 480,
          "elapsed": 1549,
          "user": {
            "displayName": "Leonardo Zepeda-Núñez",
            "userId": "15785928026062780104"
          }
        },
        "outputId": "b62d6398-02fb-444a-f557-be661f1dbccc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the low-res data using a simple sub-sampling\n",
        "u_lr_hf = u_hr[:, :, ::ds_x]\n",
        "x_lr_hf = x_[::ds_x]\n",
        "u_lr_lf = u_lr\n",
        "\n",
        "print(f\"Shape of the low-resolution high-fidelity data {u_lr_hf.shape}\")\n",
        "print(f\"Shape of the low-resolution grid {x_lr_hf.shape}\")\n",
        "print(f\"Shape of the low-resolution low-fidelity data {u_lr_lf.shape}\")"
      ],
      "metadata": {
        "id": "ZKfF6iz3ImJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732068724046,
          "user_tz": 480,
          "elapsed": 318,
          "user": {
            "displayName": "Leonardo Zepeda-Núñez",
            "userId": "15785928026062780104"
          }
        },
        "outputId": "fe327293-bdd8-423b-b32e-ee208f991a44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot marginal histograms for all times.\n",
        "spatial_idx_x = 1\n",
        "\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.hist(u_lr[:, :, spatial_idx_x].flatten(), \n",
        "         bins=100,\n",
        "         alpha=0.5,\n",
        "         density=True,\n",
        "         label='Finite Volumes')\n",
        "plt.hist(u_lr_hf[:, :, spatial_idx_x].flatten(),\n",
        "         bins=100,\n",
        "         alpha=0.5,\n",
        "         density=True,\n",
        "         label='Pseudo Spectral')\n",
        "plt.legend()\n",
        "plt.title(\"Histograms for the high- and low-fidelity solutions\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jLOyvGXNIpSF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732068724566,
          "user_tz": 480,
          "elapsed": 521,
          "user": {
            "displayName": "Leonardo Zepeda-Núñez",
            "userId": "15785928026062780104"
          }
        },
        "outputId": "440fa04f-a755-4942-c8e1-6776c8af9262"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Further downsample in time and space.\n",
        "time_subsample  = 1\n",
        "space_subsample = 1\n",
        "\n",
        "x_src = u_lr_lf[:,::time_subsample,::space_subsample]\n",
        "x_trgt = u_lr_hf[:,::time_subsample,::space_subsample]\n",
        "\n",
        "# We squeeze all the data (scramble the time-step and trajectory information).\n",
        "x_src = x_src.reshape((-1, x_src.shape[-1]))\n",
        "x_trgt = x_trgt.reshape((-1, x_trgt.shape[-1]))\n",
        "\n",
        "print(f'Total data set size source: {x_src.shape} target: {x_trgt.shape}')\n",
        "\n",
        "# Define training and test data split.\n",
        "train_split = 0.9\n",
        "test_split  = 0.1\n",
        "\n",
        "# Define sample sizes.\n",
        "n_train = int(np.floor(x_src.shape[0]*train_split))\n",
        "n_eval = int(np.floor(x_src.shape[0]*test_split))\n",
        "\n",
        "# Divide samples.\n",
        "x_src_train = x_src[:n_train,:]\n",
        "x_trgt_train = x_trgt[:n_train,:]\n",
        "\n",
        "x_src_valid = x_src[n_train:,:]\n",
        "x_trgt_valid = x_trgt[n_train:,:]\n",
        "\n",
        "print('Training data set size')\n",
        "print(f\"Shape of the source training data: {x_src_train.shape}\")\n",
        "print(f\"Shape of the target training data: {x_trgt_train.shape}\")\n",
        "\n",
        "print('Validation data set size')\n",
        "print(f\"Shape of the source validation data: {x_src_valid.shape}\")\n",
        "print(f\"Shape of the target validation data: {x_trgt_valid.shape}\")\n",
        "\n",
        "del u_hr"
      ],
      "metadata": {
        "id": "YrfWdCscIvtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732068724566,
          "user_tz": 480,
          "elapsed": 4,
          "user": {
            "displayName": "Leonardo Zepeda-Núñez",
            "userId": "15785928026062780104"
          }
        },
        "outputId": "6ca52e4d-a493-455b-bfb0-67d790c4a951"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute distance between distributions.\n",
        "@jax.jit\n",
        "def sinkhorn_loss(x: jax.Array, y: jax.Array, epsilon: float=0.1) -\u003e jax.Array:\n",
        "    \"\"\"Computes transport between (x, a) and (y, b) via Sinkhorn algorithm.\"\"\"\n",
        "    # We assume equal weights for all points.\n",
        "    a = jnp.ones(len(x)) / len(x)\n",
        "    b = jnp.ones(len(y)) / len(y)\n",
        "\n",
        "    sdiv = sinkhorn_divergence.sinkhorn_divergence(\n",
        "        pointcloud.PointCloud, x, y, epsilon=epsilon, a=a, b=b\n",
        "    )\n",
        "\n",
        "    return sdiv[0]\n"
      ],
      "metadata": {
        "id": "1p2NGzx8I0p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sinkhorn Iteration\n",
        "\n",
        "Here we instatiate the solver leveraging jax-ott. As the complexity of the Sinkhorn iteration is quadratic on the number of datapoints, we use a smaller data set (with a adjustable size) so the computation is realtively fast. In order to obtaining a transport map with better metrics, a larger n_max would be needed."
      ],
      "metadata": {
        "id": "i-pKMLiVI7Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximum number of points to be used for the transport.\n",
        "# (this takes around 30 seconds to compute with an A100)\n",
        "n_max = 20_040\n",
        "\n",
        "momentum = ott.solvers.linear.acceleration.Momentum(value=.5)\n",
        "\n",
        "# Defining the geometry.\n",
        "geom = pointcloud.PointCloud(x_src_train[:n_max],\n",
        "                             x_trgt_train[:n_max],\n",
        "                             epsilon=0.001)\n",
        "\n",
        "# Computing the potentials.\n",
        "out = sinkhorn.Sinkhorn(max_iterations=1000,\n",
        "                        momentum=momentum,\n",
        "                        parallel_dual_updates=True)(\n",
        "                            linear_problem.LinearProblem(geom))\n",
        "dual_potentials = out.to_dual_potentials()"
      ],
      "metadata": {
        "id": "tvkTy_XKI9WT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing the sinkhorn divergence."
      ],
      "metadata": {
        "id": "MQeYyMWWXHT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute sinkhorn distance before transport.\n",
        "sinkhorn_dist = sinkhorn_loss(x_src_train[:n_max],\n",
        "                              x_trgt_train[:n_max],\n",
        "                              epsilon=0.001)\n",
        "print(f\"Sinkhorn distance between source and target data: {sinkhorn_dist:.3f}\")\n",
        "\n",
        "# Compute sinkhorn distance after transport.\n",
        "tx_src_train = dual_potentials.transport(x_src_train[:n_max])\n",
        "sinkhorn_dist = sinkhorn_loss(tx_src_train,\n",
        "                              x_trgt_train[:n_max],\n",
        "                              epsilon=0.001)\n",
        "print(f\"Sinkhorn distance between transported source and target data: {sinkhorn_dist:.3f}\")\n",
        "\n",
        "# Compute validation distance.\n",
        "tx_src_valid = dual_potentials.transport(x_src_valid[:n_max])\n",
        "sinkhorn_dist = sinkhorn_loss(tx_src_valid,\n",
        "                              x_trgt_valid[:n_max],\n",
        "                              epsilon=0.001)\n",
        "print(f\"Sinkhorn distance (validation) between transported source and target data: {sinkhorn_dist:.3f}\")"
      ],
      "metadata": {
        "id": "XqIdRtA-JOmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732069161563,
          "user_tz": 480,
          "elapsed": 142255,
          "user": {
            "displayName": "Leonardo Zepeda-Núñez",
            "userId": "15785928026062780104"
          }
        },
        "outputId": "7bc3f57c-b787-47c2-b12d-14b1e5765ed4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing distributions"
      ],
      "metadata": {
        "id": "gmafvGYpXa95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transports the validation set.\n",
        "tx_src_valid = np.array(dual_potentials.transport(x_src_valid))"
      ],
      "metadata": {
        "id": "OVbeK6RPJSjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We fix one point in space to plot the histograms.\n",
        "idx_x = 2\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(x_src_valid[:, idx_x], bins=50, density=True,\n",
        "         alpha=0.5, label='Finite Volumes')\n",
        "plt.hist(x_trgt_valid[:, idx_x], bins=50, density=True,\n",
        "         alpha=0.5, label='Pseudo Spectral')\n",
        "plt.hist(tx_src_valid[:, idx_x], bins=50, density=True,\n",
        "         alpha=0.5, label='Finite Volumes Debiased')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OmVIl1RiJUYS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732069295288,
          "user_tz": 480,
          "elapsed": 565,
          "user": {
            "displayName": "Leonardo Zepeda-Núñez",
            "userId": "15785928026062780104"
          }
        },
        "outputId": "c005833c-ea28-4c18-a9e5-5b86219bcee1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
