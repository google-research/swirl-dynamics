{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIW-If53CiPL"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czOvyn7HCbgV"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/google-research/swirl-dynamics.git@main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2DJBuEdCpFc"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP6GQNwnCrwz"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDKhSAGaCrk2"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "\n",
        "from clu import metric_writers\n",
        "import jax\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import optax\n",
        "import orbax.checkpoint as ocp\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from swirl_dynamics import templates\n",
        "from swirl_dynamics.lib import diffusion as dfn_lib\n",
        "from swirl_dynamics.lib import solvers as solver_lib\n",
        "from swirl_dynamics.projects import probabilistic_diffusion as dfn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ylBqVdcCvcz"
      },
      "source": [
        "## Example I - Unconditional diffusion model with guidance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVzRTpB5Dgm2"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THwrp-2UD2iS"
      },
      "source": [
        "First we need a dataset containing samples whose distribution is to be modeled by the diffusion model. For demonstration purpose, we use the MNIST dataset provided by TensorFlow Datasets.\n",
        "\n",
        "Our code setup accepts any Python iterable objects to be used as dataloaders. The expectation is that they should continuously yield a dictionary with a field named `x` whose corresponding value is a numpy array with shape `(batch, *spatial_dims, channels)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRf3AcadCvKj"
      },
      "outputs": [],
      "source": [
        "def get_mnist_dataset(split: str, batch_size: int):\n",
        "  ds = tfds.load(\"mnist\", split=split)\n",
        "  ds = ds.map(\n",
        "      # Change field name from \"image\" to \"x\" (required by `DenoisingModel`)\n",
        "      # and normalize the value to [0, 1].\n",
        "      lambda x: {\"x\": tf.cast(x[\"image\"], tf.float32) / 255.0}\n",
        "  )\n",
        "  ds = ds.repeat()\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "  ds = ds.as_numpy_iterator()\n",
        "  return ds\n",
        "\n",
        "# The standard deviation of the normalized dataset.\n",
        "# This is useful for determining the diffusion scheme and preconditioning\n",
        "# of the neural network parametrization.\n",
        "DATA_STD = 0.31"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5tZdk5eEQhh"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA4hHUeHEVoE"
      },
      "source": [
        "Next let's define the U-Net backbone. The \"Preconditioning\" is to ensure that the inputs and outputs of the network are roughly standardized (for more details, see Appendix B.6. in [this paper](https://arxiv.org/abs/2206.00364))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE1-wf7aETEH"
      },
      "outputs": [],
      "source": [
        "denoiser_model = dfn_lib.PreconditionedDenoiserUNet(\n",
        "    out_channels=1,\n",
        "    num_channels=(64, 128),\n",
        "    downsample_ratio=(2, 2),\n",
        "    num_blocks=4,\n",
        "    noise_embed_dim=128,\n",
        "    padding=\"SAME\",\n",
        "    use_attention=True,\n",
        "    use_position_encoding=True,\n",
        "    num_heads=8,\n",
        "    sigma_data=DATA_STD,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Htjx7TxAEsKW"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5i7oh2WFFU0"
      },
      "source": [
        "For diffusion model training, the above-defined U-Net backbone serves as a denoiser, which takes as input a batch of (isotropic Gaussian noise) corrupted samples and outputs its best guess for what the uncorrupted image would be.\n",
        "\n",
        "Besides the backbone architecture, we also need to specify how to sample the noise levels (i.e. standard deviations) used to corrupt the samples and the weighting for each noise level in the loss function (for available options and configurations, see [`swirl_dynamics.lib.diffusion.diffusion`](https://github.com/google-research/swirl-dynamics/blob/main/swirl_dynamics/lib/diffusion/diffusion.py)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l52TFsPEEp5u"
      },
      "outputs": [],
      "source": [
        "diffusion_scheme = dfn_lib.Diffusion.create_variance_exploding(\n",
        "    sigma=dfn_lib.tangent_noise_schedule(),\n",
        "    data_std=DATA_STD,\n",
        ")\n",
        "\n",
        "model = dfn.DenoisingModel(\n",
        "    # `input_shape` must agree with the expected sample shape (without the batch\n",
        "    # dimension), which in this case is simply the dimensions of a single MNIST\n",
        "    # sample.\n",
        "    input_shape=(28, 28, 1),\n",
        "    denoiser=denoiser_model,\n",
        "    noise_sampling=dfn_lib.log_uniform_sampling(\n",
        "        diffusion_scheme, clip_min=1e-4, uniform_grid=True,\n",
        "    ),\n",
        "    noise_weighting=dfn_lib.edm_weighting(data_std=DATA_STD),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76a8RhUpFLoe"
      },
      "source": [
        "We are now ready to define the learning parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8fl_R1gEp36"
      },
      "outputs": [],
      "source": [
        "# !rm -R -f $workdir  # optional: clear the working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4DAOL_xEp1k"
      },
      "outputs": [],
      "source": [
        "num_train_steps = 100_000  #@param\n",
        "workdir = \"/tmp/diffusion_demo_mnist\"  #@param\n",
        "train_batch_size = 32  #@param\n",
        "eval_batch_size = 32  #@param\n",
        "initial_lr = 0.0  #@param\n",
        "peak_lr = 1e-4  #@param\n",
        "warmup_steps = 1000  #@param\n",
        "end_lr = 1e-6  #@param\n",
        "ema_decay = 0.999  #@param\n",
        "ckpt_interval = 1000  #@param\n",
        "max_ckpt_to_keep = 5  #@param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr-be7CiFRhp"
      },
      "source": [
        "To start training, we first need to initialize the trainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7E4WZUFEpzv"
      },
      "outputs": [],
      "source": [
        "# NOTE: use `trainers.DistributedDenoisingTrainer` for multi-device\n",
        "# training with data parallelism.\n",
        "trainer = dfn.DenoisingTrainer(\n",
        "    model=model,\n",
        "    rng=jax.random.PRNGKey(888),\n",
        "    optimizer=optax.adam(\n",
        "        learning_rate=optax.warmup_cosine_decay_schedule(\n",
        "            init_value=initial_lr,\n",
        "            peak_value=peak_lr,\n",
        "            warmup_steps=warmup_steps,\n",
        "            decay_steps=num_train_steps,\n",
        "            end_value=end_lr,\n",
        "        ),\n",
        "    ),\n",
        "    # We keep track of an exponential moving average of the model parameters\n",
        "    # over training steps. This alleviates the \"color-shift\" problems known to\n",
        "    # exist in the diffusion models.\n",
        "    ema_decay=ema_decay,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTQf9w1NFgp7"
      },
      "source": [
        "Now we are ready to kick start training. A couple of \"callbacks\" are passed to assist with monitoring and checkpointing.\n",
        "\n",
        "The first step will be a little slow as Jax needs to JIT compile the step function (the same goes for the first step where evaluation is performed). Fortunately, steps after that should continue much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMQbydfdEpxQ"
      },
      "outputs": [],
      "source": [
        "templates.run_train(\n",
        "    train_dataloader=get_mnist_dataset(\n",
        "        split=\"train[:75%]\", batch_size=train_batch_size\n",
        "    ),\n",
        "    trainer=trainer,\n",
        "    workdir=workdir,\n",
        "    total_train_steps=num_train_steps,\n",
        "    metric_writer=metric_writers.create_default_writer(\n",
        "        workdir, asynchronous=False\n",
        "    ),\n",
        "    metric_aggregation_steps=100,\n",
        "    eval_dataloader=get_mnist_dataset(\n",
        "        split=\"train[75%:]\", batch_size=eval_batch_size\n",
        "    ),\n",
        "    eval_every_steps = 1000,\n",
        "    num_batches_per_eval = 2,\n",
        "    callbacks=(\n",
        "        # This callback displays the training progress in a tqdm bar\n",
        "        templates.TqdmProgressBar(\n",
        "            total_train_steps=num_train_steps,\n",
        "            train_monitors=(\"train_loss\",),\n",
        "        ),\n",
        "        # This callback saves model checkpoint periodically\n",
        "        templates.TrainStateCheckpoint(\n",
        "            base_dir=workdir,\n",
        "            options=ocp.CheckpointManagerOptions(\n",
        "                save_interval_steps=ckpt_interval, max_to_keep=max_ckpt_to_keep\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJDsoPMcFnJ0"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGPHjX8bFqrX"
      },
      "source": [
        "#### Unconditional generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUHa793NF0AS"
      },
      "source": [
        "After training is complete, the trained denoiser may be used to generate unconditional samples.\n",
        "\n",
        "First, let's restore the model from checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-CbKOV9EpvI"
      },
      "outputs": [],
      "source": [
        "# Restore train state from checkpoint. By default, the move recently saved\n",
        "# checkpoint is restored. Alternatively, one can directly use\n",
        "# `trainer.train_state` if continuing from the training section above.\n",
        "trained_state = dfn.DenoisingModelTrainState.restore_from_orbax_ckpt(\n",
        "    f\"{workdir}/checkpoints\", step=None\n",
        ")\n",
        "# Construct the inference function\n",
        "denoise_fn = dfn.DenoisingTrainer.inference_fn_from_state_dict(\n",
        "    trained_state, use_ema=True, denoiser=denoiser_model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT2c5b6FF9jP"
      },
      "source": [
        "Diffusion samples are generated by plugging the trained denoising function in a stochastic differential equation (parametrized by the diffusion scheme) and solving it backwards in time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiOByVtjEpUs"
      },
      "outputs": [],
      "source": [
        "sampler = dfn_lib.SdeSampler(\n",
        "    input_shape=(28, 28, 1),\n",
        "    integrator=solver_lib.EulerMaruyama(),\n",
        "    tspan=dfn_lib.edm_noise_decay(\n",
        "        diffusion_scheme, rho=7, num_steps=256, end_sigma=1e-3,\n",
        "    ),\n",
        "    scheme=diffusion_scheme,\n",
        "    denoise_fn=denoise_fn,\n",
        "    guidance_transforms=(),\n",
        "    apply_denoise_at_end=True,\n",
        "    return_full_paths=False,  # Set to `True` if the full sampling paths are needed\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA26cPp0GBwC"
      },
      "source": [
        "The sampler may be run by calling its `.generate()` function. Optionally, we may JIT compile this function so that it runs faster if repeatedly called."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7yaiI7NF_61"
      },
      "outputs": [],
      "source": [
        "generate = jax.jit(sampler.generate, static_argnames=('num_samples',))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qUxgUaKGENj"
      },
      "outputs": [],
      "source": [
        "samples = generate(\n",
        "    rng=jax.random.PRNGKey(8888), num_samples=4\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTjpNNHtGH9c"
      },
      "source": [
        "Visualize the generated samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thhRfIe5GELQ"
      },
      "outputs": [],
      "source": [
        "# Plot generated samples\n",
        "fig, ax = plt.subplots(1, 4, figsize=(8, 2))\n",
        "for i in range(4):\n",
        "  im = ax[i].imshow(samples[i, :, :, 0] * 255, cmap=\"gray\", vmin=0, vmax=255)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Cr6J3hfGLi7"
      },
      "source": [
        "#### Guided generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8-3Hr5IGReH"
      },
      "source": [
        "To achieve 'guided' generation, we can modify a trained denoising function and tailor it to produce samples with specific desired characteristics. For instance, in an out-filling task where the goal is to generate full images from a given patch, we can guide the denoiser to create samples whose crops at certain positions precisely align with the provided patch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7P4li0qGEI4"
      },
      "outputs": [],
      "source": [
        "guidance_fn = dfn_lib.InfillFromSlices(\n",
        "    # This specifies location of the guide input using python slices.\n",
        "    # Here it implies that the guide input corresponds the 7x7 patch in the\n",
        "    # center of the image.\n",
        "    slices=(slice(None), slice(11, 18), slice(11, 18)),\n",
        "\n",
        "    # This is a parameter that controls how \"hard\" the denoiser pushes for\n",
        "    # the conditioning to be satisfied. It is a tradeoff between strictness of\n",
        "    # constraint satisfication and diversity in the generated samples.\n",
        "    guide_strength=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D5zBynzGUdY"
      },
      "source": [
        "This transform function is passed through the `guidance_transforms` arg of the sampler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_kJnXqjGEGz"
      },
      "outputs": [],
      "source": [
        "guided_sampler = dfn_lib.SdeSampler(\n",
        "    input_shape=(28, 28, 1),\n",
        "    integrator=solver_lib.EulerMaruyama(),\n",
        "    tspan=dfn_lib.edm_noise_decay(\n",
        "        diffusion_scheme, rho=7, num_steps=256, end_sigma=1e-3,\n",
        "    ),\n",
        "    scheme=diffusion_scheme,\n",
        "    denoise_fn=denoise_fn,\n",
        "    guidance_transforms=(guidance_fn,),\n",
        "    apply_denoise_at_end=True,\n",
        "    return_full_paths=False,\n",
        ")\n",
        "\n",
        "guided_generate = jax.jit(guided_sampler.generate, static_argnames=('num_samples',))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcDPFQ9PGX9-"
      },
      "source": [
        "We construct an example guidance input from a real sample and use it to guide the sampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5Uap93nGEEx"
      },
      "outputs": [],
      "source": [
        "test_ds = get_mnist_dataset(split=\"test\", batch_size=1)\n",
        "test_example = next(iter(test_ds))[\"x\"]\n",
        "example_guidance_inputs = {'observed_slices': test_example[:, 11:18, 11:18]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdUrseQOGECo"
      },
      "outputs": [],
      "source": [
        "guided_samples = guided_generate(\n",
        "    rng=jax.random.PRNGKey(66),\n",
        "    num_samples=4,\n",
        "    # Note that the shape of the guidance input must be compatible with\n",
        "    # `sample[guidance_fn.slices]`\n",
        "    guidance_inputs=example_guidance_inputs,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auf-UA3yGew-"
      },
      "source": [
        "Visualize guided samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72jBzmTCGEAg"
      },
      "outputs": [],
      "source": [
        "# Plot guide patch.\n",
        "fig, ax = plt.subplots(1, 1, figsize=(2, 2))\n",
        "im = ax.imshow(\n",
        "    test_example[0, 11:18, 11:18, 0] * 255, cmap=\"gray\", vmin=0, vmax=255\n",
        ")\n",
        "ax.axis(\"off\")\n",
        "ax.set_title(\"Guide patch\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot generated samples.\n",
        "fig, ax = plt.subplots(1, 4, figsize=(8, 2))\n",
        "for i in range(4):\n",
        "  im = ax[i].imshow(\n",
        "      guided_samples[i, :, :, 0] * 255, cmap=\"gray\", vmin=0, vmax=255\n",
        "  )\n",
        "  # Mark out the patch where guidance is enabled.\n",
        "  square = patches.Rectangle(\n",
        "      xy=(11, 11), width=7, height=7, fill=False, edgecolor='red'\n",
        "  )\n",
        "  ax[i].add_patch(square)\n",
        "  ax[i].axis(\"off\")\n",
        "  ax[i].set_title(f\"Sample #{i}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq4xz1w9GkFE"
      },
      "source": [
        "## Example II - Conditional diffusion model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElgwVoIPGxRq"
      },
      "source": [
        "In the above example, we trained an *unconditional* diffusion model and applied conditioning at inference time. This is not always easy to do, depending on how the conditioning input relates to the samples.\n",
        "\n",
        "Alternatively, we can directly *train a conditional model*, where the conditional signal is provided at training time as an additional input to the denoising neural network, which may then use it to compute the denoised target.\n",
        "\n",
        "Below we show an example of how to accomplish this. We again generate samples of handwritten digits, using the MNIST dataset for training. We will condition the generation on the `x[11:18, 11:18]` patch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U-O2msbGzEx"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba3Wn2YvG1oC"
      },
      "source": [
        "Besides the sample in `x`, the dataset for training conditional models require a `cond` key which contains the condition signals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IpRYEJtGD-Q"
      },
      "outputs": [],
      "source": [
        "def preproc_example(example: dict[str, tf.Tensor]):\n",
        "  processed = {}\n",
        "  processed[\"x\"] = tf.cast(example[\"image\"], tf.float32) / 255.0\n",
        "\n",
        "  # The \"channel:\" prefix indicate that the conditioning signal is to be\n",
        "  # incorporated by resizing and concatenating along the channel dimension.\n",
        "  # This is implemented at the backbone level.\n",
        "  processed[\"cond\"] = {\"channel:low_res\": processed[\"x\"][11:18, 11:18]}\n",
        "  return processed\n",
        "\n",
        "\n",
        "def get_cond_mnist_dataset(split: str, batch_size: int):\n",
        "  ds = tfds.load(\"mnist\", split=split)\n",
        "  ds = ds.map(preproc_example)\n",
        "  ds = ds.repeat()\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "  ds = ds.as_numpy_iterator()\n",
        "  return ds\n",
        "\n",
        "DATA_STD = 0.31"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yOBMiJtG7r3"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNUY5kQG9xd"
      },
      "source": [
        "The architecture is similar to the unconditional case. We provide additional args that specify how to resize the conditioning signal (in order to be compatible with the noisy sample for channel-wise concatenation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5F8kNMAGiTR"
      },
      "outputs": [],
      "source": [
        "cond_denoiser_model = dfn_lib.PreconditionedDenoiserUNet(\n",
        "    out_channels=1,\n",
        "    num_channels=(64, 128),\n",
        "    downsample_ratio=(2, 2),\n",
        "    num_blocks=4,\n",
        "    noise_embed_dim=128,\n",
        "    padding=\"SAME\",\n",
        "    use_attention=True,\n",
        "    use_position_encoding=True,\n",
        "    num_heads=8,\n",
        "    sigma_data=DATA_STD,\n",
        "    cond_resize_method=\"cubic\",\n",
        "    cond_embed_dim=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19oJrFsjHCIZ"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT0JP9yAHEem"
      },
      "source": [
        "The `DenoisingModel` is again similar to the unconditional case. We additionally provide the shape information of the `cond` input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJFKb060GiRH"
      },
      "outputs": [],
      "source": [
        "diffusion_scheme = dfn_lib.Diffusion.create_variance_exploding(\n",
        "    sigma=dfn_lib.tangent_noise_schedule(),\n",
        "    data_std=DATA_STD,\n",
        ")\n",
        "\n",
        "cond_model = dfn.DenoisingModel(\n",
        "    input_shape=(28, 28, 1),\n",
        "    # `cond_shape` must agree with the expected structure and shape\n",
        "    # (without the batch dimension) of the `cond` input.\n",
        "    cond_shape={\"channel:low_res\": (7, 7, 1)},\n",
        "    denoiser=cond_denoiser_model,\n",
        "    noise_sampling=dfn_lib.log_uniform_sampling(\n",
        "        diffusion_scheme, clip_min=1e-4, uniform_grid=True,\n",
        "    ),\n",
        "    noise_weighting=dfn_lib.edm_weighting(data_std=DATA_STD),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81Bktr9gHHjz"
      },
      "source": [
        "The rest mostly repeats the unconditional training example, replacing the datasets and model with their conditional counterparts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyEsCCSbGiPC"
      },
      "outputs": [],
      "source": [
        "# !rm -R -f $cond_workdir  # optional: clear the working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekXD8PprGiM8"
      },
      "outputs": [],
      "source": [
        "num_train_steps = 100_000  #@param\n",
        "cond_workdir = \"/tmp/cond_diffusion_demo_mnist\"  #@param\n",
        "train_batch_size = 32  #@param\n",
        "eval_batch_size = 32  #@param\n",
        "initial_lr = 0.0  #@param\n",
        "peak_lr = 1e-4  #@param\n",
        "warmup_steps = 1000  #@param\n",
        "end_lr = 1e-6  #@param\n",
        "ema_decay = 0.999  #@param\n",
        "ckpt_interval = 1000  #@param\n",
        "max_ckpt_to_keep = 5  #@param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DDpmV-zGiKW"
      },
      "outputs": [],
      "source": [
        "cond_trainer = dfn.DenoisingTrainer(\n",
        "    model=cond_model,\n",
        "    rng=jax.random.PRNGKey(888),\n",
        "    optimizer=optax.adam(\n",
        "        learning_rate=optax.warmup_cosine_decay_schedule(\n",
        "            init_value=initial_lr,\n",
        "            peak_value=peak_lr,\n",
        "            warmup_steps=warmup_steps,\n",
        "            decay_steps=num_train_steps,\n",
        "            end_value=end_lr,\n",
        "        ),\n",
        "    ),\n",
        "    ema_decay=ema_decay,\n",
        ")\n",
        "\n",
        "templates.run_train(\n",
        "    train_dataloader=get_cond_mnist_dataset(\n",
        "        split=\"train[:75%]\", batch_size=train_batch_size\n",
        "    ),\n",
        "    trainer=cond_trainer,\n",
        "    workdir=cond_workdir,\n",
        "    total_train_steps=num_train_steps,\n",
        "    metric_writer=metric_writers.create_default_writer(\n",
        "        cond_workdir, asynchronous=False\n",
        "    ),\n",
        "    metric_aggregation_steps=100,\n",
        "    eval_dataloader=get_cond_mnist_dataset(\n",
        "        split=\"train[75%:]\", batch_size=eval_batch_size\n",
        "    ),\n",
        "    eval_every_steps = 1000,\n",
        "    num_batches_per_eval = 2,\n",
        "    callbacks=(\n",
        "        templates.TqdmProgressBar(\n",
        "            total_train_steps=num_train_steps,\n",
        "            train_monitors=(\"train_loss\",),\n",
        "        ),\n",
        "        templates.TrainStateCheckpoint(\n",
        "            base_dir=cond_workdir,\n",
        "            options=ocp.CheckpointManagerOptions(\n",
        "                save_interval_steps=ckpt_interval, max_to_keep=max_ckpt_to_keep\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojUo2JDEHPCN"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS0m_f0CHR5i"
      },
      "source": [
        "To perform inference/sampling, let's load back the trained conditional model checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RHlke6pGiHx"
      },
      "outputs": [],
      "source": [
        "trained_state = dfn.DenoisingModelTrainState.restore_from_orbax_ckpt(\n",
        "    f\"{cond_workdir}/checkpoints\", step=None\n",
        ")\n",
        "# Construct the inference function\n",
        "cond_denoise_fn = dfn.DenoisingTrainer.inference_fn_from_state_dict(\n",
        "    trained_state, use_ema=True, denoiser=cond_denoiser_model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3crKP7hqHV7I"
      },
      "source": [
        "The conditional sampler again follows the previous example, with the only exception being that the conditional model replaces the unconditional one.\n",
        "\n",
        "Below we do not apply any guidance, but one can be easily added in the same way as in the unconditional example above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnaFzOjOHOu4"
      },
      "outputs": [],
      "source": [
        "cond_sampler = dfn_lib.SdeSampler(\n",
        "    input_shape=(28, 28, 1),\n",
        "    integrator=solver_lib.EulerMaruyama(),\n",
        "    tspan=dfn_lib.edm_noise_decay(\n",
        "        diffusion_scheme, rho=7, num_steps=256, end_sigma=1e-3,\n",
        "    ),\n",
        "    scheme=diffusion_scheme,\n",
        "    denoise_fn=cond_denoise_fn,\n",
        "    guidance_transforms=(),\n",
        "    apply_denoise_at_end=True,\n",
        "    return_full_paths=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lYF1OUEHZFM"
      },
      "source": [
        "We again JIT the generate function for the sake of faster repeated sampling calls. Here we employ `functools.partial` to specify `num_samples=5`, making it easier to vectorize across the batch dimension with `jax.vmap`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT_rLzdgHOsm"
      },
      "outputs": [],
      "source": [
        "num_samples_per_cond = 5\n",
        "\n",
        "generate = jax.jit(\n",
        "    functools.partial(cond_sampler.generate, num_samples_per_cond)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_9TfCMSHd3P"
      },
      "source": [
        "Loading a test batch of conditions with 4 elements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tODWrPBfHOqN"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "test_ds = get_cond_mnist_dataset(split=\"test\", batch_size=4)\n",
        "test_batch_cond = next(iter(test_ds))[\"cond\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HJXzAtzHhli"
      },
      "source": [
        "The vectorized generate function is applied to the loaded batch. The vectorization occurs for the leading dimensions of both the random seed and the condition (for those unfamiliarized with vectorized operations in jax, think of a more efficient `for` loop that iterates over the random seeds and batch conditions zipped together)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29oPpGuWHhYP"
      },
      "outputs": [],
      "source": [
        "cond_samples = jax.vmap(generate, in_axes=(0, 0, None))(\n",
        "    jax.random.split(jax.random.PRNGKey(8888), batch_size),\n",
        "    test_batch_cond,\n",
        "    None,  # Guidance inputs = None since no guidance transforms involved\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH9CozY8Hkgv"
      },
      "source": [
        "The result `cond_samples` has shape `(batch_size, num_samples_per_cond, *input_shape)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSQHV5FmHOoK"
      },
      "outputs": [],
      "source": [
        "print(cond_samples.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br6clK2cHow9"
      },
      "source": [
        "Visualize generated examples alongside their low-res conditioning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7c5wXDcHOkP"
      },
      "outputs": [],
      "source": [
        "for i in range(batch_size):\n",
        "  fig, ax = plt.subplots(1, 1, figsize=(2, 2))\n",
        "  im = ax.imshow(\n",
        "      test_batch_cond[\"channel:low_res\"][i, :, :, 0] * 255,\n",
        "      cmap=\"gray\", vmin=0, vmax=255\n",
        "  )\n",
        "  ax.axis(\"off\")\n",
        "  ax.set_title(f\"Low-res condition: #{i + 1}\")\n",
        "\n",
        "\n",
        "  # Plot generated samples.\n",
        "  fig, ax = plt.subplots(\n",
        "      1, num_samples_per_cond, figsize=(num_samples_per_cond * 2, 2)\n",
        "  )\n",
        "  for j in range(num_samples_per_cond):\n",
        "    im = ax[j].imshow(\n",
        "        cond_samples[i, j, :, :, 0] * 255, cmap=\"gray\", vmin=0, vmax=255\n",
        "    )\n",
        "    square = patches.Rectangle(\n",
        "        xy=(11, 11), width=7, height=7, fill=False, edgecolor='red'\n",
        "    )\n",
        "    ax[j].add_patch(square)\n",
        "    ax[j].set_title(f\"conditional sample: #{j + 1}\")\n",
        "    ax[j].axis(\"off\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "A100",
      "last_runtime": {
        "build_target": "//learning/grp/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1eA8hF0r-tUgIX-miyPgPkzH80WjzCarp",
          "timestamp": 1707268348992
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
