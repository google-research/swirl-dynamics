# Copyright 2025 The swirl_dynamics Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Conditional denoising model with sampling CRPS evaluation."""

from collections.abc import Mapping
import dataclasses
import functools
from typing import Any

import jax
import jax.numpy as jnp
import numpy as np
from swirl_dynamics.lib import diffusion as dfn_lib
from swirl_dynamics.lib import metrics as metric_lib
from swirl_dynamics.lib import solvers as solver_lib
from swirl_dynamics.projects.probabilistic_diffusion import models as dfn_models
from swirl_dynamics.templates import models

Array = jax.Array
BatchType = Mapping[str, Any]
PyTree = Any


@dataclasses.dataclass(frozen=True, kw_only=True)
class DenoisingModel(dfn_models.DenoisingModel):
  """Denoising diffusion model with additional eval metrics for downscaling.

  Besides denoising RMSE at different noise levels, additional eval metrics
  include CRPS of the samples generated by a sampling SDE and eval data log
  likelihood computed from the probability flow ODE. Some generated samples
  are also returned from evaluation for visualization.

  Attributes:
    diffusion_scheme: The diffusion scheme for SDE and ODE samplers.
    cg_strength: Classifier guidance strength. This assumes that the underlying
      diffusion model is hybrid unconditional and conditional.
    num_sde_steps: The number of integration steps for solving the sampling SDE.
    num_samples_per_condition: The number of samples to generate per condition
      during evaluation. These samples will be generated in one single batch.
    num_ode_steps: The number of integration steps for likelihood evaluation
      using the ODE probability flow.
    num_likelihood_probes: The number of probes for approximating the log
      likelihood of eval samples.
  """

  diffusion_scheme: dfn_lib.Diffusion
  cg_strength: float = 0.3
  num_sde_steps: int = 128
  num_samples_per_condition: int = 4
  num_ode_steps: int = 64
  num_likelihood_probes: int = 4

  def eval_fn(
      self, variables: models.PyTree, batch: models.BatchType, rng: Array
  ) -> models.ArrayDict:
    """Compute metrics on an eval batch."""
    rng_denoise, rng_sample, rng_likelihood = jax.random.split(rng, num=3)
    denoising_metrics = self.denoising_eval(variables, batch, rng_denoise)
    sampling_metrics = self.sampling_eval(variables, batch, rng_sample)
    likelihood_metrics = self.likelihood_eval(variables, batch, rng_likelihood)
    return dict(**denoising_metrics, **sampling_metrics, **likelihood_metrics)

  def sampling_eval(
      self, variables: models.PyTree, batch: models.BatchType, rng: Array
  ) -> models.ArrayDict:
    """Compute sampling metrics on an eval batch."""
    sde_sampler = self.get_sde_sampler(variables)
    sampling_fn = functools.partial(
        sde_sampler.generate, self.num_samples_per_condition
    )
    samples = jax.vmap(sampling_fn, in_axes=(0, 0, 0))(
        jax.random.split(rng, batch["x"].shape[0]),
        batch["cond"],
        batch.get("guidance_inputs", {}),
    )  # ~ (batch, samples, *sample_dims)
    crps = jnp.mean(metric_lib.crps(forecasts=samples, observations=batch["x"]))
    return {
        # Take first batch element and one sample only. The batch axis is kept
        # to work with `CollectingMetric` in clu.
        "example_sample": jnp.asarray(samples)[:1, 0],
        "example_input": batch["cond"]["channel:daily_mean"][:1],
        "example_obs": batch["x"][:1],
        "mean_crps": crps,
    }  # pytype: disable=bad-return-type

  def likelihood_eval(
      self, variables: PyTree, batch: BatchType, rng: Array
  ) -> models.ArrayDict:
    """Evaluates the log likelihood using the ODE probability flow.

    The likelihood of eval data is approximated using the instantaneous change
    of variable formula (see `dfn_lib.OdeSampler.compute_log_likelihood()` for
    more details), computed with the probability flow ODE.

    Args:
      variables: Variables for the denoising model.
      batch: A batch of evaluation data.
      rng: A Jax random key.

    Returns:
      Likelihood of the eval samples per dimension.
    """
    ode_sampler = self.get_ode_sampler(variables)
    sample_log_likelihood = ode_sampler.compute_log_likelihood(
        inputs=batch["x"],
        cond=batch["cond"],
        guidance_inputs=batch.get("guidance_inputs", {}),
        eps=jax.random.normal(
            key=rng,
            shape=(
                batch["x"].shape[0],
                self.num_likelihood_probes,
                *self.input_shape,
            ),
        ),
    )
    return {
        "sample_log_likelihood_per_dim": jnp.mean(
            sample_log_likelihood / np.prod(self.input_shape)
        )
    }

  def get_sde_sampler(self, variables: PyTree) -> dfn_lib.SdeSampler:
    """Constructs a SDE sampler from given denoising model variables."""
    return dfn_lib.SdeSampler(
        input_shape=self.input_shape,
        denoise_fn=self.inference_fn(variables, self.denoiser),
        integrator=solver_lib.EulerMaruyama(iter_type="loop"),  # Save memory.
        scheme=self.diffusion_scheme,
        guidance_transforms=(
            dfn_lib.ClassifierFreeHybrid(guidance_strength=self.cg_strength),
        ),
        tspan=dfn_lib.edm_noise_decay(
            self.diffusion_scheme, num_steps=self.num_sde_steps
        ),
    )

  def get_ode_sampler(self, variables: PyTree) -> dfn_lib.OdeSampler:
    """Constructs an ODE sampler from given denoising model variables."""
    return dfn_lib.OdeSampler(
        input_shape=self.input_shape,
        denoise_fn=self.inference_fn(variables, self.denoiser),
        integrator=solver_lib.HeunsMethod(),
        scheme=self.diffusion_scheme,
        guidance_transforms=(
            dfn_lib.ClassifierFreeHybrid(guidance_strength=self.cg_strength),
        ),
        tspan=dfn_lib.edm_noise_decay(
            self.diffusion_scheme, num_steps=self.num_ode_steps
        ),
    )
